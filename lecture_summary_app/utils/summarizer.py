def generate_summary(text_data_list, api_key, output_language="ja", ai_provider="gemini"):
    """
    Generates a summary from a list of text data.
    text_data_list: List of dicts with 'content' and 'source'.
    output_language: 'ja' for Japanese, 'en' for English, etc.
    ai_provider: 'gemini' or 'openai'
    """
    import os
    
    # ç’°å¢ƒå¤‰æ•°ã«ç¢ºå®Ÿã«APIã‚­ãƒ¼ã‚’è¨­å®š
    if ai_provider == "openai":
        os.environ["OPENAI_API_KEY"] = api_key
    else:
        os.environ["GOOGLE_API_KEY"] = api_key
    
    # Lazy imports to prevent startup errors
    if ai_provider == "openai":
        from langchain_openai import ChatOpenAI
        llm = ChatOpenAI(model="gpt-3.5-turbo", openai_api_key=api_key, temperature=0.7)
    else:
        from langchain_google_genai import ChatGoogleGenerativeAI
        # Geminiã®æœ€æ–°ãƒ¢ãƒ‡ãƒ«åï¼ˆtemperatureè¨­å®šã§é«˜é€ŸåŒ–ï¼‰
        # APIã‚­ãƒ¼ã‚’æ˜ç¤ºçš„ã«æ¸¡ã™
        llm = ChatGoogleGenerativeAI(
            model="gemini-2.0-flash-exp",  # æœ€æ–°ã®é«˜é€Ÿãƒ¢ãƒ‡ãƒ«
            google_api_key=api_key,  # APIã‚­ãƒ¼ã‚’æ˜ç¤ºçš„ã«æ¸¡ã™
            temperature=0.3,  # ä½æ¸©åº¦ã§é«˜é€ŸåŒ–ã¨ä¸€è²«æ€§å‘ä¸Š
            max_tokens=4096   # ãƒˆãƒ¼ã‚¯ãƒ³æ•°åˆ¶é™ã§é«˜é€ŸåŒ–
        )
    
    if not text_data_list:
        return {"summary": "No content to summarize.", "integration": "No content available."}

    # è¨€èªè¨­å®š
    language_instruction = {
        "ja": "ã™ã¹ã¦ã®å‡ºåŠ›ã¯æ—¥æœ¬èªã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚",
        "en": "Please write all output in English."
    }.get(output_language, "ã™ã¹ã¦ã®å‡ºåŠ›ã¯æ—¥æœ¬èªã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚")

    # Combine all text content
    full_text = ""
    for item in text_data_list:
        full_text += f"\n\n--- Source: {item['source']} ---\n"
        full_text += item['content']

    # LLM is already initialized above based on ai_provider

    # 1. Generate Summaryï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæœ€é©åŒ–ã§é«˜é€ŸåŒ–ï¼‰
    summary_prompt = f"""
    {language_instruction}
    
    è¤‡æ•°ã®è¬›ç¾©è³‡æ–™ã‚’çµ±åˆã—ã€é‡è¤‡ã‚’æ•´ç†ã—ã¦ä½“ç³»çš„ãªå­¦ç¿’ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
    
    ã€å¿…é ˆè¦ä»¶ã€‘
    1. åŒã˜ãƒˆãƒ”ãƒƒã‚¯ã¯çµ±åˆã—ã¦1ã¤ã«ã¾ã¨ã‚ã‚‹
    2. å…±é€šãƒ†ãƒ¼ãƒã§è¦‹å‡ºã—ã‚’ä½œæˆ
    3. ã™ã¹ã¦ã®é‡è¦æƒ…å ±ã‚’å«ã‚ã‚‹
    4. å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«å‡ºå…¸ã‚’æ˜è¨˜: `[å‡ºå…¸: ãƒ•ã‚¡ã‚¤ãƒ«å]`
    5. LaTeXæ•°å¼ã‚’ä¿æŒ: $E=mc^2$, $\\\\frac{{d}}{{dx}}$
    
    ã€å‡ºåŠ›å½¢å¼ã€‘
    # [ã‚¿ã‚¤ãƒˆãƒ«]
    
    ## 1. [ãƒˆãƒ”ãƒƒã‚¯å]
    - è©³ç´°è§£èª¬
    - å…·ä½“ä¾‹
    `[å‡ºå…¸: ãƒ•ã‚¡ã‚¤ãƒ«å]`
    
    ## ğŸ“š é‡è¦ç”¨èªé›†
    - ç”¨èª: å®šç¾©
    
    ã€è³‡æ–™ã€‘
    {full_text}
    """
    
    import time
    max_retries = 3  # ãƒªãƒˆãƒ©ã‚¤å›æ•°å‰Šæ¸›ï¼ˆé«˜é€ŸåŒ–ï¼‰
    retry_delay = 10  # 10ç§’å¾…æ©Ÿï¼ˆé«˜é€ŸåŒ–ï¼‰
    
    summary_result = None
    
    # Generate Summary
    print("ğŸ“ è¦ç´„ã‚’ç”Ÿæˆä¸­...")
    for attempt in range(max_retries):
        try:
            response = llm.invoke(summary_prompt)
            summary_result = response.content
            print("âœ… è¦ç´„ç”Ÿæˆå®Œäº†")
            break
        except Exception as e:
            error_str = str(e)
            if "RESOURCE_EXHAUSTED" in error_str or "429" in error_str or "TOO_MANY_REQUESTS" in error_str:
                if attempt < max_retries - 1:
                    wait_time = retry_delay * (attempt + 1)
                    print(f"â³ ãƒ¬ãƒ¼ãƒˆåˆ¶é™: {wait_time}ç§’å¾…æ©Ÿä¸­... (è©¦è¡Œ {attempt+1}/{max_retries})")
                    time.sleep(wait_time)
                    continue
                else:
                    summary_result = f"âš ï¸ è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼: APIã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚30ç§’å¾Œã«å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚"
            else:
                summary_result = f"âš ï¸ è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {type(e).__name__} - {str(e)[:100]}"
            break
    
    if not summary_result:
        summary_result = "âš ï¸ è¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
    
    # 2. Generate Integration Summary (ã¾ã¨ã‚) - å¾…æ©Ÿæ™‚é–“ãªã—ï¼ˆé«˜é€ŸåŒ–ï¼‰
    integration_prompt = f"""
    {language_instruction}
    
    è¤‡æ•°ã®è³‡æ–™ã‹ã‚‰æœ€é‡è¦ãƒã‚¤ãƒ³ãƒˆã¨å…¨ä½“ã®æµã‚Œã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚
    
    ã€å¿…é ˆè¦ä»¶ã€‘
    1. æœ€ã‚‚é‡è¦ãª3~5ã¤ã®ãƒã‚¤ãƒ³ãƒˆã‚’æ˜ç¢ºã«
    2. å„è³‡æ–™ã®é–¢ä¿‚æ€§ã¨æµã‚Œã‚’ç¤ºã™
    3. å‡ºå…¸ã‚’æ˜è¨˜: `[å‡ºå…¸: ãƒ•ã‚¡ã‚¤ãƒ«å]`
    
    ã€å‡ºåŠ›å½¢å¼ã€‘
    # ğŸ“Œ å…¨ä½“ã¾ã¨ã‚
    
    ## ã€æœ€é‡è¦ãƒã‚¤ãƒ³ãƒˆã€‘
    - ãƒã‚¤ãƒ³ãƒˆ1 `[å‡ºå…¸: ãƒ•ã‚¡ã‚¤ãƒ«å]`
    - ãƒã‚¤ãƒ³ãƒˆ2 `[å‡ºå…¸: ãƒ•ã‚¡ã‚¤ãƒ«å]`
    
    ## ã€å…¨ä½“ã®æµã‚Œã€‘
    [è³‡æ–™å…¨ä½“ã®æµã‚Œã‚’ç°¡æ½”ã«èª¬æ˜]
    
    ## ã€å®Ÿè·µçš„å¿œç”¨ã€‘
    [å­¦ã‚“ã ã“ã¨ã®æ´»ç”¨æ–¹æ³•]
    
    ã€è³‡æ–™ã€‘
    {full_text[:5000]}
    """
    
    integration_result = None
    
    # Generate Integration Summary
    print("ğŸ“‹ ã¾ã¨ã‚ã‚’ç”Ÿæˆä¸­...")
    for attempt in range(max_retries):
        try:
            response = llm.invoke(integration_prompt)
            integration_result = response.content
            print("âœ… ã¾ã¨ã‚ç”Ÿæˆå®Œäº†")
            break
        except Exception as e:
            error_str = str(e)
            if "RESOURCE_EXHAUSTED" in error_str or "429" in error_str or "TOO_MANY_REQUESTS" in error_str:
                if attempt < max_retries - 1:
                    wait_time = retry_delay * (attempt + 1)
                    print(f"â³ ãƒ¬ãƒ¼ãƒˆåˆ¶é™: {wait_time}ç§’å¾…æ©Ÿä¸­... (è©¦è¡Œ {attempt+1}/{max_retries})")
                    time.sleep(wait_time)
                    continue
                else:
                    integration_result = f"âš ï¸ ã¾ã¨ã‚ç”Ÿæˆã‚¨ãƒ©ãƒ¼: APIã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚30ç§’å¾Œã«å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚"
            else:
                integration_result = f"âš ï¸ ã¾ã¨ã‚ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {type(e).__name__} - {str(e)[:100]}"
            break
    
    if not integration_result:
        integration_result = "âš ï¸ ã¾ã¨ã‚ç”Ÿæˆã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
    
    return {
        "summary": summary_result or "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ",
        "integration": integration_result or "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"
    }

