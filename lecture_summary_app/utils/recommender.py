def recommend_sources(summary_text, api_key, skip_if_not_found=True, ai_provider="gemini"):
    """
    Analyzes the summary to find key topics and searches for high-quality external resources.
    skip_if_not_found: Trueã®å ´åˆã€è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°ç©ºãƒªã‚¹ãƒˆã‚’è¿”ã™ï¼ˆç„¡ç†ã«æ¢ã•ãªã„ï¼‰
    ai_provider: 'gemini' or 'openai'
    """
    from .web_loader import search_web
    
    if ai_provider == "openai":
        from langchain_openai import ChatOpenAI
        llm = ChatOpenAI(model="gpt-3.5-turbo", openai_api_key=api_key, temperature=0.7)
    else:
        from langchain_google_genai import ChatGoogleGenerativeAI
        llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", google_api_key=api_key)
    
    # 1. Extract Keywords
    prompt = f"""
    ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€å­¦è¡“çš„ãªè³‡æ–™ã‚„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’æ¤œç´¢ã™ã‚‹ãŸã‚ã®é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰3ã¤ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
    ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ã¿ã‚’ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã§è¿”ã—ã¦ãã ã•ã„ã€‚
    
    ãƒ†ã‚­ã‚¹ãƒˆ: {summary_text[:1000]}
    """
    
    try:
        response = llm.invoke(prompt)
        keywords = response.content.strip()
        print(f"ğŸ” æŠ½å‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keywords}")
    except Exception as e:
        print(f"âš ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        if skip_if_not_found:
            return []  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºãƒªã‚¹ãƒˆã‚’è¿”ã™
        keywords = summary_text[:100] if summary_text else "å­¦ç¿’ è³‡æ–™ ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«"

    # 2. Search Web (1å›ã®ã¿)
    try:
        # é«˜å“è³ªãªã‚½ãƒ¼ã‚¹ã‚’å„ªå…ˆã™ã‚‹æ¤œç´¢ã‚¯ã‚¨ãƒª
        search_query = f"{keywords} tutorial documentation OR site:.ac.jp OR site:.edu OR site:wikipedia"
        print(f"ğŸŒ Webæ¤œç´¢ä¸­: {search_query}")
        results = search_web(search_query, max_results=5)
        
        if results and len(results) > 0:
            print(f"âœ… {len(results)}ä»¶ã®é–¢é€£è³‡æ–™ã‚’ç™ºè¦‹")
            return results
        else:
            print("â„¹ï¸ é–¢é€£è³‡æ–™ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            if skip_if_not_found:
                return []  # è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°ç©ºãƒªã‚¹ãƒˆã‚’è¿”ã™
            else:
                return [{
                    "title": "ğŸ“š é–¢é€£è³‡æ–™ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ",
                    "href": "https://www.google.com/search?q=" + keywords.replace(" ", "+"),
                    "body": f"ã€Œ{keywords}ã€ã§Googleæ¤œç´¢ã—ã¦ã¿ã¦ãã ã•ã„ã€‚"
                }]
    except Exception as e:
        print(f"âŒ Webæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return []  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ç©ºãƒªã‚¹ãƒˆ

def manual_search(query, max_results=5):
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ‰‹å‹•ã§é–¢é€£è³‡æ–™ã‚’æ¤œç´¢ã™ã‚‹æ©Ÿèƒ½
    """
    from .web_loader import search_web
    
    try:
        print(f"ğŸ” æ‰‹å‹•æ¤œç´¢: {query}")
        # å®‰å…¨ãªæ¤œç´¢ã‚¯ã‚¨ãƒªã«å¤‰æ›
        safe_query = query + " site:.ac.jp OR site:.edu OR site:wikipedia OR tutorial"
        results = search_web(safe_query, max_results=max_results)
        
        if results and len(results) > 0:
            print(f"âœ… {len(results)}ä»¶ã®è³‡æ–™ã‚’ç™ºè¦‹")
            return results
        else:
            return [{
                "title": "æ¤œç´¢çµæœãªã—",
                "href": f"https://www.google.com/search?q={query.replace(' ', '+')}",
                "body": f"ã€Œ{query}ã€ã®æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚Googleã§æ¤œç´¢ã—ã¦ã¿ã¦ãã ã•ã„ã€‚"
            }]
    except Exception as e:
        print(f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        return [{
            "title": "æ¤œç´¢ã‚¨ãƒ©ãƒ¼",
            "href": "https://www.google.com",
            "body": f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        }]
